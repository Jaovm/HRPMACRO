import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import requests
from sklearn.covariance import LedoitWolf
from scipy.cluster.hierarchy import linkage, dendrogram
from scipy.spatial.distance import squareform
from scipy.optimize import minimize

# ========= DICION√ÅRIOS ==========

setores_por_ticker = {
    # Bancos
    'ITUB4.SA': 'Bancos',
    'BBDC4.SA': 'Bancos',
    'SANB11.SA': 'Bancos',
    'BBAS3.SA': 'Bancos',
    'ABCB4.SA': 'Bancos',
    'BRSR6.SA': 'Bancos',
    'BMGB4.SA': 'Bancos',
    'BPAC11.SA': 'Bancos',

    # Seguradoras
    'BBSE3.SA': 'Seguradoras',
    'PSSA3.SA': 'Seguradoras',
    'SULA11.SA': 'Seguradoras',
    'CXSE3.SA': 'Seguradoras',

    # Bolsas e Servi√ßos Financeiros
    'B3SA3.SA': 'Bolsas e Servi√ßos Financeiros',
    'XPBR31.SA': 'Bolsas e Servi√ßos Financeiros',

    # Energia El√©trica
    'EGIE3.SA': 'Energia El√©trica',
    'CPLE6.SA': 'Energia El√©trica',
    'TAEE11.SA': 'Energia El√©trica',
    'CMIG4.SA': 'Energia El√©trica',
    'AURE3.SA': 'Energia El√©trica',
    'CPFE3.SA': 'Energia El√©trica',
    'AESB3.SA': 'Energia El√©trica',

    # Petr√≥leo, G√°s e Biocombust√≠veis
    'PETR4.SA': 'Petr√≥leo, G√°s e Biocombust√≠veis',
    'PRIO3.SA': 'Petr√≥leo, G√°s e Biocombust√≠veis',
    'RECV3.SA': 'Petr√≥leo, G√°s e Biocombust√≠veis',
    'RRRP3.SA': 'Petr√≥leo, G√°s e Biocombust√≠veis',
    'UGPA3.SA': 'Petr√≥leo, G√°s e Biocombust√≠veis',
    'VBBR3.SA': 'Petr√≥leo, G√°s e Biocombust√≠veis',

    # Minera√ß√£o e Siderurgia
    'VALE3.SA': 'Minera√ß√£o e Siderurgia',
    'CSNA3.SA': 'Minera√ß√£o e Siderurgia',
    'GGBR4.SA': 'Minera√ß√£o e Siderurgia',
    'CMIN3.SA': 'Minera√ß√£o e Siderurgia',
    'GOAU4.SA': 'Minera√ß√£o e Siderurgia',
    'BRAP4.SA': 'Minera√ß√£o e Siderurgia',

    # Ind√∫stria e Bens de Capital
    'WEGE3.SA': 'Ind√∫stria e Bens de Capital',
    'RANI3.SA': 'Ind√∫stria e Bens de Capital',
    'KLBN11.SA': 'Ind√∫stria e Bens de Capital',
    'SUZB3.SA': 'Ind√∫stria e Bens de Capital',
    'UNIP6.SA': 'Ind√∫stria e Bens de Capital',
    'KEPL3.SA': 'Ind√∫stria e Bens de Capital',

    # Agroneg√≥cio
    'AGRO3.SA': 'Agroneg√≥cio',
    'SLCE3.SA': 'Agroneg√≥cio',
    'SMTO3.SA': 'Agroneg√≥cio',
    'CAML3.SA': 'Agroneg√≥cio',

    # Sa√∫de
    'HAPV3.SA': 'Sa√∫de',
    'FLRY3.SA': 'Sa√∫de',
    'RDOR3.SA': 'Sa√∫de',
    'QUAL3.SA': 'Sa√∫de',
    'RADL3.SA': 'Sa√∫de',

    # Tecnologia
    'TOTS3.SA': 'Tecnologia',
    'POSI3.SA': 'Tecnologia',
    'LINX3.SA': 'Tecnologia',
    'LWSA3.SA': 'Tecnologia',

    # Consumo Discricion√°rio
    'MGLU3.SA': 'Consumo Discricion√°rio',
    'LREN3.SA': 'Consumo Discricion√°rio',
    'RENT3.SA': 'Consumo Discricion√°rio',
    'ARZZ3.SA': 'Consumo Discricion√°rio',
    'ALPA4.SA': 'Consumo Discricion√°rio',

    # Consumo B√°sico
    'ABEV3.SA': 'Consumo B√°sico',
    'NTCO3.SA': 'Consumo B√°sico',
    'PCAR3.SA': 'Consumo B√°sico',
    'MDIA3.SA': 'Consumo B√°sico',

    # Comunica√ß√£o
    'VIVT3.SA': 'Comunica√ß√£o',
    'TIMS3.SA': 'Comunica√ß√£o',
    'OIBR3.SA': 'Comunica√ß√£o',

    # Utilidades P√∫blicas
    'SBSP3.SA': 'Utilidades P√∫blicas',
    'SAPR11.SA': 'Utilidades P√∫blicas',
    'CSMG3.SA': 'Utilidades P√∫blicas',
    'ALUP11.SA': 'Utilidades P√∫blicas',
    'CPLE6.SA': 'Utilidades P√∫blicas',
}


setores_por_cenario = {
    "Expansionista": [
        'Consumo Discricion√°rio',
        'Tecnologia',
        'Ind√∫stria e Bens de Capital',
        'Agroneg√≥cio'
    ],
    "Neutro": [
        'Sa√∫de',
        'Bancos',
        'Seguradoras',
        'Bolsas e Servi√ßos Financeiros',
        'Utilidades P√∫blicas'
    ],
    "Restritivo": [
        'Energia El√©trica',
        'Petr√≥leo, G√°s e Biocombust√≠veis',
        'Minera√ß√£o e Siderurgia',
        'Consumo B√°sico',
        'Comunica√ß√£o'
    ]
}

setor_favorecido = setores_por_cenario.get(cenario_macro, [])

empresas_exportadoras = [
    'VALE3.SA',  # Minera√ß√£o
    'SUZB3.SA',  # Celulose
    'KLBN11.SA', # Papel e Celulose
    'AGRO3.SA',  # Agroneg√≥cio
    'PRIO3.SA',  # Petr√≥leo
    'SLCE3.SA',  # Agroneg√≥cio
    'SMTO3.SA',  # A√ß√∫car e Etanol
    'CSNA3.SA',  # Siderurgia
    'GGBR4.SA',  # Siderurgia
    'CMIN3.SA',  # Minera√ß√£o
]


# ========= MACRO ==========
def get_bcb(code):
    url = f"https://api.bcb.gov.br/dados/serie/bcdata.sgs.{code}/dados/ultimos/1?formato=json"
    r = requests.get(url)
    return float(r.json()[0]['valor'].replace(",", ".")) if r.status_code == 200 else None

def obter_preco_petroleo():
    try:
        dados = yf.Ticker("CL=F").history(period="5d")
        if not dados.empty and 'Close' in dados.columns:
            return float(dados['Close'].dropna().iloc[-1])
        else:
            return None
    except Exception as e:
        st.error(f"Erro ao obter pre√ßo do petr√≥leo: {e}")
        return None

def obter_macro():
    return {
        "selic": get_bcb(432),
        "ipca": get_bcb(433),
        "dolar": get_bcb(1),
        "petroleo": obter_preco_petroleo()
    }

def classificar_cenario_macro(m):
    if m['ipca'] > 5 or m['selic'] > 12:
        return "Restritivo"
    elif m['ipca'] < 4 and m['selic'] < 10:
        return "Expansionista"
    else:
        return "Neutro"

# ========= PRE√áO ALVO ==========

def obter_preco_diario_ajustado(tickers, periodo='7y'):
    dados = yf.download(tickers, period=periodo, group_by='ticker', auto_adjust=True)
    if len(tickers) == 1:
        return dados['Adj Close'].to_frame()
    else:
        return dados['Adj Close']


def otimizar_carteira_sharpe(tickers):
    dados = obter_preco_diario_ajustado(tickers)
    retornos = dados.pct_change().dropna()
    media_retorno = retornos.mean()
    cov = LedoitWolf().fit(retornos).covariance_

    def sharpe_neg(pesos):
        retorno_esperado = np.dot(pesos, media_retorno)
        volatilidade = np.sqrt(np.dot(pesos.T, np.dot(cov, pesos)))
        return -retorno_esperado / volatilidade if volatilidade != 0 else 0

    n = len(tickers)
    pesos_iniciais = np.array([1/n] * n)
    limites = [(0, 1) for _ in range(n)]
    restricoes = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}

    resultado = minimize(sharpe_neg, pesos_iniciais, method='SLSQP', bounds=limites, constraints=restricoes)

    if resultado.success:
        return resultado.x
    else:
        return None

def obter_preco_alvo(ticker):
    try:
        return yf.Ticker(ticker).info.get('targetMeanPrice', None)
    except:
        return None

def obter_preco_atual(ticker):
    try:
        return yf.Ticker(ticker).history(period="1d")['Close'].iloc[-1]
    except:
        return None

# ========= FILTRAR A√á√ïES ==========
def calcular_score(preco_atual, preco_alvo, favorecido, ticker, macro):
    upside = (preco_alvo - preco_atual) / preco_atual
    bonus = 0.1 if favorecido else 0
    if ticker in empresas_exportadoras:
        if macro['dolar'] and macro['dolar'] > 5:
            bonus += 0.05
        if macro['petroleo'] and macro['petroleo'] > 80:
            bonus += 0.05
    return upside + bonus

def filtrar_ativos_validos(carteira, cenario, macro):
    setores_bons = setores_por_cenario[cenario]
    ativos_validos = []

    for ticker in carteira:
        setor = setores_por_ticker.get(ticker, None)
        preco_atual = obter_preco_atual(ticker)
        preco_alvo = obter_preco_alvo(ticker)

        if preco_atual is None or preco_alvo is None:
            continue
        if preco_atual < preco_alvo:
            favorecido = setor in setores_bons
            score = calcular_score(preco_atual, preco_alvo, favorecido, ticker, macro)
            ativos_validos.append({
                "ticker": ticker,
                "setor": setor,
                "preco_atual": preco_atual,
                "preco_alvo": preco_alvo,
                "favorecido": favorecido,
                "score": score
            })

    ativos_validos.sort(key=lambda x: x['score'], reverse=True)
    return ativos_validos

# ========= OTIMIZA√á√ÉO ==========
def obter_preco_diario_ajustado(tickers):
    dados_brutos = yf.download(tickers, period="3y", auto_adjust=False)

    if isinstance(dados_brutos.columns, pd.MultiIndex):
        if 'Adj Close' in dados_brutos.columns.get_level_values(0):
            return dados_brutos['Adj Close']
        elif 'Close' in dados_brutos.columns.get_level_values(0):
            return dados_brutos['Close']
        else:
            raise ValueError("Colunas 'Adj Close' ou 'Close' n√£o encontradas nos dados.")
    else:
        if 'Adj Close' in dados_brutos.columns:
            return dados_brutos[['Adj Close']].rename(columns={'Adj Close': tickers[0]})
        elif 'Close' in dados_brutos.columns:
            return dados_brutos[['Close']].rename(columns={'Close': tickers[0]})
        else:
            raise ValueError("Coluna 'Adj Close' ou 'Close' n√£o encontrada nos dados.")

def otimizar_carteira_hrp(tickers):
    dados = obter_preco_diario_ajustado(tickers)
    retornos = dados.pct_change().dropna()
    dist = np.sqrt(((1 - retornos.corr()) / 2).fillna(0))
    linkage_matrix = linkage(squareform(dist), method='single')

def get_quasi_diag(link):
    link = link.astype(int)
    sort_ix = pd.Series([link[-1, 0], link[-1, 1]])
    num_items = link[-1, 3]
    while sort_ix.max() >= num_items:
        sort_ix.index = range(0, sort_ix.shape[0]*2, 2)
        df0 = sort_ix[sort_ix >= num_items]
        i = df0.index
        j = df0.values - num_items
        sort_ix[i] = link[j, 0]
        df1 = pd.Series(link[j, 1], index=i+1)
        sort_ix = pd.concat([sort_ix, df1])
        sort_ix = sort_ix.sort_index()
        sort_ix.index = range(sort_ix.shape[0])
    return sort_ix.tolist()


    sort_ix = get_quasi_diag(linkage_matrix)
    sorted_tickers = [retornos.columns[i] for i in sort_ix]
    cov = LedoitWolf().fit(retornos).covariance_
    ivp = 1. / np.diag(cov)
    ivp /= ivp.sum()

    def get_cluster_var(cov, cluster_items):
        cov_slice = cov[np.ix_(cluster_items, cluster_items)]
        w_ = 1. / np.diag(cov_slice)
        w_ /= w_.sum()
        return np.dot(w_, np.dot(cov_slice, w_))

    def recursive_bisection(cov, sort_ix):
        w = pd.Series(1, index=sort_ix)
        cluster_items = [sort_ix]
        while len(cluster_items) > 0:
            cluster_items = [i[j:k] for i in cluster_items for j, k in ((0, len(i) // 2), (len(i) // 2, len(i))) if len(i) > 1]
            for i in range(0, len(cluster_items), 2):
                c0 = cluster_items[i]
                c1 = cluster_items[i + 1]
                var0 = get_cluster_var(cov, c0)
                var1 = get_cluster_var(cov, c1)
                alpha = 1 - var0 / (var0 + var1)
                w[c0] *= alpha
                w[c1] *= 1 - alpha
        return w

    hrp_weights = recursive_bisection(cov, list(range(len(tickers))))
    return hrp_weights.values


st.subheader("üìà Ranking de Oportunidades de Compra")

# Identifica setor favorecido
setor_favorecido = setores_por_cenario.get(cenario_macro, [])
df_carteira_atual['Setor'] = df_carteira_atual['Ticker'].map(setores_por_ticker)
df_carteira_atual['Favorecido?'] = df_carteira_atual['Setor'].isin(setor_favorecido)

# Pre√ßo atual + pre√ßo-alvo
df_carteira_atual['Pre√ßo Atual'] = df_carteira_atual['Ticker'].apply(lambda x: get_info_yf(x).get("currentPrice", None))
df_carteira_atual['Pre√ßo Alvo'] = df_carteira_atual['Ticker'].apply(lambda x: get_info_yf(x).get("targetMeanPrice", None))
df_carteira_atual['Potencial Upside'] = (df_carteira_atual['Pre√ßo Alvo'] / df_carteira_atual['Pre√ßo Atual']) - 1

# Ranking por setor favorecido + upside
ranking = df_carteira_atual[df_carteira_atual['Favorecido?']].sort_values('Potencial Upside', ascending=False)
st.dataframe(ranking[['Ticker', 'Setor', 'Pre√ßo Atual', 'Pre√ßo Alvo', 'Potencial Upside']].style.format({
    'Pre√ßo Atual': 'R$ {:.2f}', 'Pre√ßo Alvo': 'R$ {:.2f}', 'Potencial Upside': '{:.2%}'
}))

st.subheader("üîÅ Nova Aloca√ß√£o com HRP")

# Baixa cota√ß√µes hist√≥ricas
tickers = df_carteira_atual['Ticker'].tolist()
prices = yf.download(tickers, period="5y", interval="1d")['Adj Close'].dropna()
returns = prices.pct_change().dropna()

# Matriz de covari√¢ncia com Ledoit-Wolf
lw = LedoitWolf()
cov_matrix = lw.fit(returns).covariance_

# HRP
hrp = HierarchicalRiskParity()
weights_hrp = hrp.allocate(asset_names=returns.columns.tolist(), cov_matrix=cov_matrix)

# Penaliza ativos de setores n√£o favorecidos
for ticker in weights_hrp.keys():
    setor = setores_por_ticker.get(ticker, None)
    if setor not in setor_favorecido:
        weights_hrp[ticker] *= 0.5  # penaliza√ß√£o leve

# Normaliza pesos novamente
total = sum(weights_hrp.values())
for t in weights_hrp:
    weights_hrp[t] /= total

# Apresenta
df_hrp = pd.DataFrame.from_dict(weights_hrp, orient='index', columns=['Peso HRP'])
df_hrp['Peso Atual'] = df_carteira_atual.set_index('Ticker')['Peso (%)']
df_hrp['Setor'] = df_hrp.index.map(setores_por_ticker)
df_hrp['Favorecido?'] = df_hrp['Setor'].isin(setor_favorecido)
st.dataframe(df_hrp.style.format({"Peso Atual": "{:.2%}", "Peso HRP": "{:.2%}"}))

st.subheader("üí∏ Sugest√£o de Aloca√ß√£o do Novo Aporte")

# Calcula valor alvo por HRP
df_hrp['Valor Ideal HRP'] = df_hrp['Peso HRP'] * (valor_total_carteira + valor_aporte)
df_hrp['Valor Atual'] = df_hrp['Peso Atual'] * valor_total_carteira
df_hrp['Sugest√£o de Compra (R$)'] = df_hrp['Valor Ideal HRP'] - df_hrp['Valor Atual']
df_hrp['Sugest√£o de Compra (R$)'] = df_hrp['Sugest√£o de Compra (R$)'].apply(lambda x: max(0, x))  # evita venda

# Normaliza sugest√µes para bater com valor do aporte
total_sugestao = df_hrp['Sugest√£o de Compra (R$)'].sum()
df_hrp['Sugest√£o Corrigida (R$)'] = df_hrp['Sugest√£o de Compra (R$)'] / total_sugestao * valor_aporte

# Exibe
df_sugestao = df_hrp[['Peso Atual', 'Peso HRP', 'Valor Atual', 'Valor Ideal HRP', 'Sugest√£o Corrigida (R$)', 'Setor', 'Favorecido?']]
st.dataframe(df_sugestao.style.format({
    "Peso Atual": "{:.2%}", "Peso HRP": "{:.2%}", 
    "Valor Atual": "R$ {:.2f}", "Valor Ideal HRP": "R$ {:.2f}", 
    "Sugest√£o Corrigida (R$)": "R$ {:.2f}"
}))

# Valor total confer√™ncia
valor_total_sugerido = df_sugestao['Sugest√£o Corrigida (R$)'].sum()
st.markdown(f"**Total sugerido: R$ {valor_total_sugerido:,.2f}**")
